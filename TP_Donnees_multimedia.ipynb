{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Données Multimédia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectifs du TP :**\n",
    "O1 définir ce que sont les données multimedia (terme multimedia, qui a plusieurs assertions + exemples\n",
    "variés, enjeux liés aux masses de données)\n",
    "O2 extraire des caractéristiques propres aux données sonores (pitch, MFCC, etc. ) et visuelles (couleur,\n",
    "forme, texture, notamment SIFT et \"sacs de mots\" et caractéristiques propres aux visages). Attention il\n",
    "faudra sans doute revoir quelques bases (Transformée de Fourier, notion de fréquence)\n",
    "O3 mesurer l'intérêt de ces caractéristiques ; savoir poser le problème plus que donner toutes les\n",
    "réponses : suggestions de quelques heuristiques et ouverture vers la sélection automatique ; aspects\n",
    "subjectifs (notion de fossé sémantique)\n",
    "O4 réutiliser de façon autonome ces savoirs dans un projet personnel\n",
    "\n",
    "● synthèse des connaissances acquises dans ce module (détaillées) ;\n",
    "● discussion critique de leur mise en œuvre sur l’activité vidéo (démonstration d’une réflexion\n",
    "personnelle face à des problèmes concrets) ;\n",
    "● description de la mise en œuvre dans le projet personnel (éventuellement) ;\n",
    "● 1 question que l’on aurait aimé approfondir (pour prendre du recul)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O1 définir ce que sont les données multimedia (terme multimedia, qui a plusieurs assertions + exemples variés, enjeux liés aux masses de données) :**\n",
    "\n",
    "Les \"données multimédia\" au sens large sont l'ensemble des informations que l'on peut extraire de contenus audiovisuels. Les exemples de contenus audiovisuels et de cas d'analyses n'ont de limite que l'imagination humaine  :\n",
    "- Transcrire un texte à partir de signaux de paroles humaine (speech to text translation, ou traduire en temps réel les paroles dans une autre langue speech to speech translation comme proposé par Skype)\n",
    "- Retrouver le titre et les auteurs à partir d'une bande sonore musicale (Shazam)\n",
    "- Identifier des visages dans une image (appareils photo, Facebook propose d'identifier automatiquement les visages de nos amis sur les photos, Google Photos propose de classer les albums par personne identifié etc.)\n",
    "- Identifier des actions dans une vidéo (travaux de recherche en cours ex:http://lear.inrialpes.fr/)\n",
    "- etc.\n",
    "\n",
    "Aujourd'hui ces contenus dont la disponibilité explose sur Internet sont l'objet d'enjeux collosaux pour leur stockage et leur accès rapide premièrement, et pour leur analyse deuxièmement afin de proposer de la valeur commerciale par l'automatisation de tâche ou la recommandation de contenus.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O2 extraire des caractéristiques propres aux données sonores (pitch, MFCC, etc. ) et visuelles (couleur, forme, texture, notamment SIFT et \"sacs de mots\" et caractéristiques propres aux visages). Attention il faudra sans doute revoir quelques bases (Transformée de Fourier, notion de fréquence) :**\n",
    "\n",
    "L'objectif que l'on se donne dans cette séquence est d'arriver à retrouver les transitions musique/parole à l'intérieur d'un enregistrement de l'émission vidéo \"le débat\".\n",
    "\n",
    "Extraction de la bande sonore :\n",
    "La bande sonore peut être extraite par l'intermédiaire de plusieurs logiciels libres disponibles (ex: ffmpeg). Pour ce TP elle nous est déjà donnée en séance en format WAVE (Waveform Audio File Format) stéréo échantillonné à 44100 bit/secondes.\n",
    "\n",
    "Nous pouvons donc directement commencer à analyser la bande sonore au travers de python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Chargement de la bande sonore en vecteur en utilisant la librairie Librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation de l'évolution spectrale de la bande sonore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation Mel Spéctrale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa, numpy as np, matplotlib.pyplot as plt, scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, sr =librosa.core.load(\"/home/reddowan/Documents/Telecom Paris/4-Multimedia/06-11-22.wav\", sr=44100, duration=180)\n",
    "\n",
    "librosa.display.waveplot(y=y,sr=sr)\n",
    "plt.title('Amplitude de la bande sonore')\n",
    "plt.xlabel('temps')\n",
    "plt.ylabel('amplitude')\n",
    "plt.show()\n",
    "\"\"\"On observe la répresentation des variations d'amplitude de la bande sonore en fonction du temps\"\"\"\n",
    "\n",
    "Y=scipy.fft(y)\n",
    "Y_mag=np.absolute(Y)\n",
    "plt.plot(Y_mag)\n",
    "plt.title('Spectre frequentiel')\n",
    "plt.xlabel('frequence')\n",
    "plt.ylabel('amplitude')\n",
    "plt.show()\n",
    "\"\"\"On observe bien la representation fréquentielle de la bande sonore. La representation \n",
    "est symétrique autour de la fréquence d'échantillonage 44100Hz conformément au théorème de Nyquist-Shannon\"\"\"\n",
    "\n",
    "S, freqs, bins, im=plt.specgram(y, NFFT=2048, noverlap=512, Fs=sr)\n",
    "plt.title('Spectre frequentiel par fenetre glissante')\n",
    "plt.xlabel('Temps (secondes)')\n",
    "plt.ylabel('Frequence (Hz)')\n",
    "plt.show()\n",
    "\"\"\"Cette representation nous donne l'évolution du spectre fréquentiel (FFT) pour une fenetre de 2048 échantillons \n",
    "du vecteur y à chaque point du spectrogramme. Entre deux points cette fenetre glisse de 2048-512 échantillons.\n",
    "On observe que la composition spectrale en basse fréquence évolue aux alentours de 10 secondes (changement de couleur).\n",
    "Nous allons rendre cette transition plus nette en utilisant la représentation mel-fréquentielle via la librairie librosa\"\"\"\n",
    "\n",
    "\n",
    "S=librosa.feature.melspectrogram(y,sr=sr)\n",
    "logS=librosa.logamplitude(S)\n",
    "librosa.display.specshow(logS,sr=sr,x_axis='time',y_axis='mel')\n",
    "plt.title('Representation du melspectrogram')\n",
    "plt.show()\n",
    "\n",
    "librosa.display.specshow(logS[0:13,:],sr=sr,x_axis='time',y_axis='mel')\n",
    "plt.title('Representation du melspectrogram')\n",
    "plt.show()\n",
    "\"\"\"Zoom sur les 13 premiers coefficients cepstraux\"\"\"\n",
    "\n",
    "librosa.display.specshow(logS[0:1,0:1500],sr=sr,x_axis='time',y_axis='mel')\n",
    "plt.title('Representation du melspectrogram')\n",
    "plt.show()\n",
    "\"\"\"Zoom sur les 2 premiers coefficients cepstraux on observe la chute d'énergie aux alentours de 10 secondes\"\"\"\n",
    "\n",
    "plt.plot(S[0,:])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"fft=librosa.core.stft(y=y)\n",
    "mfcc=librosa.feature.mfcc(y=y,sr=sr,n_mfcc=13)\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
